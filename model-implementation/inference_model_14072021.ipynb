{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "from jetbot import Robot\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.svm import OneClassSVM\n",
    "import random\n",
    "import collections\n",
    "\n",
    "\n",
    "#from jetbot.zmq_camera import ZmqCamera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 12, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(12, 24, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(24)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(24*53*53, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(-1,24*53*53)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = Net()\n",
    "state_dict1 = torch.load('best_model1_pruned.pth')\n",
    "net1.load_state_dict(state_dict1)\n",
    "net1 = net1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = Net()\n",
    "state_dict2 = torch.load('best_model2_pruned.pth')\n",
    "net2.load_state_dict(state_dict2)\n",
    "net2 = net2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net3 = Net()\n",
    "state_dict3 = torch.load('best_model3_pruned.pth')\n",
    "net3.load_state_dict(state_dict3)\n",
    "net3 = net3.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve normalisation parameters \n",
    "\n",
    "norm_param_df = pd.read_csv('TRG_DATASET_NORM_PARAM.csv')\n",
    "\n",
    "meanR = norm_param_df.loc[norm_param_df[\"Dataset\"] == \"AVG\", \"meanR\"].item()\n",
    "meanG = norm_param_df.loc[norm_param_df[\"Dataset\"] == \"AVG\", \"meanG\"].item()\n",
    "meanB = norm_param_df.loc[norm_param_df[\"Dataset\"] == \"AVG\", \"meanB\"].item()\n",
    "\n",
    "stdR = norm_param_df.loc[norm_param_df[\"Dataset\"] == \"AVG\", \"stdR\"].item()\n",
    "stdG = norm_param_df.loc[norm_param_df[\"Dataset\"] == \"AVG\", \"stdG\"].item()\n",
    "stdB = norm_param_df.loc[norm_param_df[\"Dataset\"] == \"AVG\", \"stdB\"].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to apply normalization parameters to camera feed\n",
    "normalize = torchvision.transforms.Normalize(255.0 * np.array([meanR, meanG, meanB]), 255.0 * np.array([stdR, stdG, stdB]))\n",
    "\n",
    "# Define function to perform pre-processing of the camera feed \n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_model = pickle.load(open('SVM_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define general layout information\n",
    "button_layout = widgets.Layout(width='128px', height='30px')\n",
    "text_layout = widgets.Layout(width='500px', height='64px')\n",
    "number_layout = widgets.Layout(width='150px', height='64px')\n",
    "\n",
    "# Define Warning interface\n",
    "holdingpoint_warning_display = widgets.Text(description='Holding Point', layout=text_layout)\n",
    "clear_button = widgets.Button(description='CLR',button_style='info', layout=button_layout)\n",
    "\n",
    "# Define Test interface\n",
    "ID_OOD_display = widgets.Text(description='ID/OOD', layout=number_layout)\n",
    "model1_prediction_display = widgets.IntText(description='Pred. 1', layout=number_layout)\n",
    "model2_prediction_display = widgets.IntText(description='Pred. 2', layout=number_layout)\n",
    "model3_prediction_display = widgets.IntText(description='Pred. 3', layout=number_layout)\n",
    "model1_proba_display = widgets.FloatText(description='Proba. 1', layout=number_layout)\n",
    "model2_proba_display = widgets.FloatText(description='Proba. 2', layout=number_layout)\n",
    "model3_proba_display = widgets.FloatText(description='Proba. 3', layout=number_layout)\n",
    "model1_proba_TS_display = widgets.FloatText(description='Proba. 1 TS', layout=number_layout, color = 'red')\n",
    "model2_proba_TS_display = widgets.FloatText(description='Proba. 2 TS', layout=number_layout)\n",
    "model3_proba_TS_display = widgets.FloatText(description='Proba. 3 TS', layout=number_layout)\n",
    "count_holdingpoint_display = widgets.IntText(description='Count', layout=number_layout)\n",
    "final_prediction_display = widgets.IntText(description='Final Pred.', layout=number_layout)\n",
    "final_prediction_TS_display = widgets.IntText(description='Final Pred. TS', layout=number_layout)\n",
    "count_excluded_display = widgets.IntText(description='Excl. %', layout=number_layout)\n",
    "count_excluded_TS_display = widgets.IntText(description='Excl. TS %', layout=number_layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Robot, Camera and Controller instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create camera instance\n",
    "camera = Camera.instance(width=224, height=224, fps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "#display(image, width = 224, height = 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect controller to Jetbot\n",
    "controller = widgets.Controller(index=0) \n",
    "display(controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create robot instance\n",
    "robot = Robot()\n",
    "# Adjust motor setting to make sure the robot goes straight \n",
    "robot = Robot(left_motor_alpha = 1.1, right_motor_alpha = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define controller functions to move the robot\n",
    "fwd_left_link = traitlets.dlink((controller.buttons[12], 'value'), (robot.left_motor, 'value'), transform=lambda x: x/8)\n",
    "fwd_right_link = traitlets.dlink((controller.buttons[12], 'value'), (robot.right_motor, 'value'), transform=lambda x: x/8)\n",
    "\n",
    "bck_left_link = traitlets.dlink((controller.buttons[13], 'value'), (robot.left_motor, 'value'), transform=lambda x: -x/8)\n",
    "bck_right_link = traitlets.dlink((controller.buttons[13], 'value'), (robot.right_motor, 'value'), transform=lambda x: -x/8)\n",
    "\n",
    "turn_left_left_link = traitlets.dlink((controller.buttons[14], 'value'), (robot.left_motor, 'value'), transform=lambda x: -x/8)\n",
    "turn_left_right_link = traitlets.dlink((controller.buttons[14], 'value'), (robot.right_motor, 'value'), transform=lambda x: x/8)\n",
    "\n",
    "turn_right_left_link = traitlets.dlink((controller.buttons[15], 'value'), (robot.left_motor, 'value'), transform=lambda x: x/8)\n",
    "turn_right_right_link = traitlets.dlink((controller.buttons[15], 'value'), (robot.right_motor, 'value'), transform=lambda x: -x/8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define update function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to compute the mean of a given channel\n",
    "def get_mean_channels(batched_outputs):\n",
    "    channel_means = []\n",
    "    for single_output in batched_outputs:\n",
    "        channel_means.append([channel.mean() for channel in single_output])\n",
    "    return torch.tensor(channel_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set counters to 0\n",
    "count_holdingpoint = 0\n",
    "count_total_cycles = 0\n",
    "count_excluded = 0\n",
    "count_excluded_TS = 0\n",
    "\n",
    "# Set confidence threshold and temperature scaling coefficient for each model (computed previously)\n",
    "threshold = 0.97\n",
    "threshold_TS = 0.73\n",
    "temp_factor_net1 = 3.661\n",
    "temp_factor_net2 = 4.289\n",
    "temp_factor_net3 = 3.913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define function to retrieve activations on the Conv2 Layer of model 1\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.cpu().detach()\n",
    "    return hook\n",
    "net1.conv2.register_forward_hook(get_activation('conv2'))\n",
    "\n",
    "# Define function that will process the images\n",
    "def update(change):\n",
    "    global count_holdingpoint, robot, count_total_cycles, count_excluded,count_excluded_TS\n",
    "    # Retrieve new live feed image\n",
    "    x = change['new'] \n",
    "    # Perform pre-processing of new live feed image\n",
    "    x = preprocess(x)\n",
    "    \n",
    "    # Run image through all three models in paralell and compute prediction\n",
    "    with torch.no_grad():  \n",
    "        net1.eval()\n",
    "        out1 = net1(x)        \n",
    "        net2.eval()\n",
    "        out2 = net2(x)        \n",
    "        net3.eval()\n",
    "        out3 = net3(x)\n",
    "        \n",
    "        # Run model 1 conv2 layer activations through SVM model to determin if image is in or out of distribution\n",
    "        OOD_prediction = SVM_model.predict(get_mean_channels(activation['conv2']))\n",
    "        if OOD_prediction == 1:\n",
    "            ID_OOD_display.value = \"ID\"\n",
    "        else:\n",
    "            ID_OOD_display.value = \"OOD\"\n",
    "        \n",
    "        # Compute and display \"raw\" prediction\n",
    "        _, prediction1 = torch.max(out1.data, 1)\n",
    "        _, prediction2 = torch.max(out2.data, 1)\n",
    "        _, prediction3 = torch.max(out3.data, 1)\n",
    "\n",
    "        model1_prediction_display.value = prediction1\n",
    "        model2_prediction_display.value = prediction2\n",
    "        model3_prediction_display.value = prediction3\n",
    "        \n",
    "        # Compute and display predictions using softmax\n",
    "        predicted_soft1 = F.softmax(out1, dim=1)\n",
    "        predicted_soft2 = F.softmax(out2, dim=1)\n",
    "        predicted_soft3 = F.softmax(out3, dim=1)\n",
    "        \n",
    "        model1_proba_display.value = np.amax(predicted_soft1.cpu().numpy())\n",
    "        model2_proba_display.value = np.amax(predicted_soft2.cpu().numpy())\n",
    "        model3_proba_display.value = np.amax(predicted_soft3.cpu().numpy())\n",
    "        \n",
    "        # Compute and display predictions using temperature scaling calibration\n",
    "        predicted_soft1_TS = F.softmax(out1/temp_factor_net1, dim=1)\n",
    "        predicted_soft2_TS = F.softmax(out2/temp_factor_net2, dim=1)\n",
    "        predicted_soft3_TS = F.softmax(out3/temp_factor_net3, dim=1)\n",
    "        \n",
    "        model1_proba_TS_display.value = np.amax(predicted_soft1_TS.cpu().numpy())\n",
    "        model2_proba_TS_display.value = np.amax(predicted_soft2_TS.cpu().numpy())\n",
    "        model3_proba_TS_display.value = np.amax(predicted_soft3_TS.cpu().numpy())\n",
    "    \n",
    "    # Perform confidence filtering (using softmax prediction)\n",
    "    if np.amax(predicted_soft1.cpu().numpy()) > threshold:\n",
    "        sure1 = 1\n",
    "    else:\n",
    "        sure1 = 0\n",
    "    if np.amax(predicted_soft2.cpu().numpy()) > threshold:\n",
    "        sure2 = 1\n",
    "    else:\n",
    "        sure2 = 0\n",
    "    if np.amax(predicted_soft3.cpu().numpy()) > threshold:\n",
    "        sure3 = 1\n",
    "    else:\n",
    "        sure3 = 0\n",
    "    \n",
    "    # Perform voting and compute final prediction (using softmax prediction)\n",
    "    if sure1 + sure2 + sure3 == 3:\n",
    "        if prediction1 + prediction2 + prediction3 >=2:\n",
    "            final_prediction = 1\n",
    "        else:\n",
    "            final_prediction = 0\n",
    "    elif sure1 + sure2 + sure3 == 2:\n",
    "        if sure1 == 0:\n",
    "            if prediction2 + prediction3 == 2:\n",
    "                final_prediction = 1\n",
    "            elif prediction2 + prediction3 == 0:\n",
    "                final_prediction = 0\n",
    "            else:\n",
    "                final_prediction = -1\n",
    "        if sure2 == 0:\n",
    "            if prediction1 + prediction3 ==2:\n",
    "                final_prediction = 1\n",
    "            elif prediction1 + prediction3 ==0:\n",
    "                final_prediction = 0\n",
    "            else:\n",
    "                final_prediction = -1\n",
    "        if sure3 == 0:\n",
    "            if prediction2 + prediction1 ==2:\n",
    "                final_prediction = 1\n",
    "            elif prediction2 + prediction1 ==0:\n",
    "                final_prediction = 0\n",
    "            else:\n",
    "                final_prediction = -1\n",
    "    else:\n",
    "        final_prediction = -1\n",
    "    \n",
    "    # Display final prediction (using softmax prediction)    \n",
    "    final_prediction_display.value = final_prediction\n",
    "    \n",
    "    # Perform confidence filtering (using temperature scaling prediction)\n",
    "    if np.amax(predicted_soft1_TS.cpu().numpy()) > threshold_TS:\n",
    "        sure1_TS = 1\n",
    "    else:\n",
    "        sure1_TS = 0\n",
    "    if np.amax(predicted_soft2_TS.cpu().numpy()) > threshold_TS:\n",
    "        sure2_TS = 1\n",
    "    else:\n",
    "        sure2_TS = 0\n",
    "    if np.amax(predicted_soft3_TS.cpu().numpy()) > threshold_TS:\n",
    "        sure3_TS = 1\n",
    "    else:\n",
    "        sure3_TS = 0\n",
    "    \n",
    "    # Perform voting and compute final prediction (using temperature scaling prediction)\n",
    "    if sure1_TS + sure2_TS + sure3_TS == 3:\n",
    "        if prediction1 + prediction2 + prediction3 >=2:\n",
    "            final_prediction_TS = 1\n",
    "        else:\n",
    "            final_prediction_TS = 0\n",
    "    elif sure1_TS + sure2_TS + sure3_TS == 2:\n",
    "        if sure1_TS == 0:\n",
    "            if prediction2 + prediction3 == 2:\n",
    "                final_prediction_TS = 1\n",
    "            elif prediction2 + prediction3 == 0:\n",
    "                final_prediction_TS = 0\n",
    "            else:\n",
    "                final_prediction_TS = -1\n",
    "        if sure2_TS == 0:\n",
    "            if prediction1 + prediction3 ==2:\n",
    "                final_prediction_TS = 1\n",
    "            elif prediction1 + prediction3 ==0:\n",
    "                final_prediction_TS = 0\n",
    "            else:\n",
    "                final_prediction_TS = -1\n",
    "        if sure3_TS == 0:\n",
    "            if prediction2 + prediction1 ==2:\n",
    "                final_prediction_TS = 1\n",
    "            elif prediction2 + prediction1 ==0:\n",
    "                final_prediction_TS = 0\n",
    "            else:\n",
    "                final_prediction_TS = -1\n",
    "    else:\n",
    "        final_prediction_TS = -1\n",
    "    \n",
    "    # Display final prediction (using temperature scaling prediction)\n",
    "    final_prediction_TS_display.value = final_prediction_TS\n",
    "    \n",
    "    # Display Alerts/Warning depending on final prediction (softmax) and counter value\n",
    "    if final_prediction == 0 and OOD_prediction == 1:\n",
    "        count_holdingpoint = count_holdingpoint + 1\n",
    "        count_holdingpoint_display.value = count_holdingpoint\n",
    "        if count_holdingpoint >=5:\n",
    "            holdingpoint_warning_display.value = \"REACHING HOLDING POINT - STOP\"\n",
    "            robot.stop()\n",
    "        else:\n",
    "            holdingpoint_warning_display.value = \"APPROACHING HOLDING POINT\"\n",
    "    else:\n",
    "        holdingpoint_warning_display.value = \" \"\n",
    "        count_holdingpoint = 0\n",
    "    \n",
    "    # Increment counter value if image was in-distribution and count number of excluded images\n",
    "    if OOD_prediction == 1:\n",
    "        count_total_cycles = count_total_cycles + 1\n",
    "        if final_prediction_TS == -1:\n",
    "            count_excluded_TS = count_excluded_TS + 1\n",
    "        if final_prediction == -1:\n",
    "            count_excluded = count_excluded + 1\n",
    "    # Compute proportion of excluded images\n",
    "    count_excluded_display.value = 100 * count_excluded / count_total_cycles\n",
    "    count_excluded_TS_display.value = 100 * count_excluded_TS / count_total_cycles\n",
    "    \n",
    "    time.sleep(0.01)\n",
    "   \n",
    "update({'new': camera.value})  # we call the function once to intialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set count to 0\n",
    "count_holdingpoint = 0\n",
    "\n",
    "# Start processing images\n",
    "camera.observe(update, names='value') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Alert/Warning field and metrics\n",
    "display(image, width = 224, height = 224)\n",
    "display(widgets.HBox([holdingpoint_warning_display, clear_button]))\n",
    "display(widgets.HBox([ID_OOD_display]))\n",
    "display(widgets.HBox([model1_prediction_display, model1_proba_display, model2_proba_TS_display]))\n",
    "display(widgets.HBox([model2_prediction_display, model2_proba_display, model1_proba_TS_display, final_prediction_display, final_prediction_TS_display, count_holdingpoint_display]))\n",
    "display(widgets.HBox([model3_prediction_display, model3_proba_display, model3_proba_TS_display, count_excluded_display, count_excluded_TS_display]))\n",
    "clear_button.on_click(lambda x: camera.unobserve(update, names='value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "camera.unobserve(update, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.unlink()  # don't stream to browser (will still run camera)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
